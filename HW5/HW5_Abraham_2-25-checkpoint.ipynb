{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### David and Abraham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libararies to undertake regression:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "sns.set()\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wage_regularization.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>educ2</th>\n",
       "      <th>educ3</th>\n",
       "      <th>educ4</th>\n",
       "      <th>educ5</th>\n",
       "      <th>age</th>\n",
       "      <th>age2</th>\n",
       "      <th>age3</th>\n",
       "      <th>age4</th>\n",
       "      <th>age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>144</td>\n",
       "      <td>1728</td>\n",
       "      <td>20736</td>\n",
       "      <td>248832</td>\n",
       "      <td>31</td>\n",
       "      <td>961</td>\n",
       "      <td>29791</td>\n",
       "      <td>923521</td>\n",
       "      <td>28629151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808000.0</td>\n",
       "      <td>18</td>\n",
       "      <td>324</td>\n",
       "      <td>5832</td>\n",
       "      <td>104976</td>\n",
       "      <td>1889568</td>\n",
       "      <td>37</td>\n",
       "      <td>1369</td>\n",
       "      <td>50653</td>\n",
       "      <td>1874161</td>\n",
       "      <td>69343957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825000.0</td>\n",
       "      <td>14</td>\n",
       "      <td>196</td>\n",
       "      <td>2744</td>\n",
       "      <td>38416</td>\n",
       "      <td>537824</td>\n",
       "      <td>33</td>\n",
       "      <td>1089</td>\n",
       "      <td>35937</td>\n",
       "      <td>1185921</td>\n",
       "      <td>39135393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>144</td>\n",
       "      <td>1728</td>\n",
       "      <td>20736</td>\n",
       "      <td>248832</td>\n",
       "      <td>32</td>\n",
       "      <td>1024</td>\n",
       "      <td>32768</td>\n",
       "      <td>1048576</td>\n",
       "      <td>33554432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>121</td>\n",
       "      <td>1331</td>\n",
       "      <td>14641</td>\n",
       "      <td>161051</td>\n",
       "      <td>34</td>\n",
       "      <td>1156</td>\n",
       "      <td>39304</td>\n",
       "      <td>1336336</td>\n",
       "      <td>45435424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage  educ  educ2  educ3   educ4    educ5  age  age2   age3     age4  \\\n",
       "0  769000.0    12    144   1728   20736   248832   31   961  29791   923521   \n",
       "1  808000.0    18    324   5832  104976  1889568   37  1369  50653  1874161   \n",
       "2  825000.0    14    196   2744   38416   537824   33  1089  35937  1185921   \n",
       "3  650000.0    12    144   1728   20736   248832   32  1024  32768  1048576   \n",
       "4  562000.0    11    121   1331   14641   161051   34  1156  39304  1336336   \n",
       "\n",
       "       age5  \n",
       "0  28629151  \n",
       "1  69343957  \n",
       "2  39135393  \n",
       "3  33554432  \n",
       "4  45435424  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Briefly looking at the head of the dataset to make sure it is the right one:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 935 entries, 0 to 934\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   wage    935 non-null    float64\n",
      " 1   educ    935 non-null    int64  \n",
      " 2   educ2   935 non-null    int64  \n",
      " 3   educ3   935 non-null    int64  \n",
      " 4   educ4   935 non-null    int64  \n",
      " 5   educ5   935 non-null    int64  \n",
      " 6   age     935 non-null    int64  \n",
      " 7   age2    935 non-null    int64  \n",
      " 8   age3    935 non-null    int64  \n",
      " 9   age4    935 non-null    int64  \n",
      " 10  age5    935 non-null    int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 80.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at the graphical distribution of the dataset (target variable: wage, and explanatory variable: educ)\n",
    "sns.scatterplot(y='wage', x='educ', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wage vs. educ graphical distribution:\n",
    "sns.scatterplot(y='wage', x='age', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1) Standardize all the variables using StandarScaler() class from sklearn package. With the standardize variables, make a new data frame and call it df_sc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sklearn library to carry out standardization:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46751952, -0.66885143, -0.681389  , -0.68346491, -0.67711629,\n",
       "        -0.66426779, -0.66971009, -0.69120265, -0.70895446, -0.72303072,\n",
       "        -0.73357606],\n",
       "       [-0.37101938,  2.06403752,  2.2236843 ,  2.37963012,  2.53086798,\n",
       "         2.67599907,  1.2619473 ,  1.28160825,  1.29793053,  1.31081019,\n",
       "         1.32021092],\n",
       "       [-0.32895523,  0.24211155,  0.1578544 ,  0.07484516, -0.00383564,\n",
       "        -0.07592792, -0.0258243 , -0.07228158, -0.11772087, -0.16164066,\n",
       "        -0.20360711]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing the standardization and viewing the first three rows: \n",
    "stand=StandardScaler()\n",
    "df_sc= stand.fit_transform(df)\n",
    "df_sc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>educ2</th>\n",
       "      <th>educ3</th>\n",
       "      <th>educ4</th>\n",
       "      <th>educ5</th>\n",
       "      <th>age</th>\n",
       "      <th>age2</th>\n",
       "      <th>age3</th>\n",
       "      <th>age4</th>\n",
       "      <th>age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.467520</td>\n",
       "      <td>-0.668851</td>\n",
       "      <td>-0.681389</td>\n",
       "      <td>-0.683465</td>\n",
       "      <td>-0.677116</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>-0.669710</td>\n",
       "      <td>-0.691203</td>\n",
       "      <td>-0.708954</td>\n",
       "      <td>-0.723031</td>\n",
       "      <td>-0.733576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.371019</td>\n",
       "      <td>2.064038</td>\n",
       "      <td>2.223684</td>\n",
       "      <td>2.379630</td>\n",
       "      <td>2.530868</td>\n",
       "      <td>2.675999</td>\n",
       "      <td>1.261947</td>\n",
       "      <td>1.281608</td>\n",
       "      <td>1.297931</td>\n",
       "      <td>1.310810</td>\n",
       "      <td>1.320211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.328955</td>\n",
       "      <td>0.242112</td>\n",
       "      <td>0.157854</td>\n",
       "      <td>0.074845</td>\n",
       "      <td>-0.003836</td>\n",
       "      <td>-0.075928</td>\n",
       "      <td>-0.025824</td>\n",
       "      <td>-0.072282</td>\n",
       "      <td>-0.117721</td>\n",
       "      <td>-0.161641</td>\n",
       "      <td>-0.203607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.761969</td>\n",
       "      <td>-0.668851</td>\n",
       "      <td>-0.681389</td>\n",
       "      <td>-0.683465</td>\n",
       "      <td>-0.677116</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>-0.347767</td>\n",
       "      <td>-0.386577</td>\n",
       "      <td>-0.422573</td>\n",
       "      <td>-0.455483</td>\n",
       "      <td>-0.485129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.979713</td>\n",
       "      <td>-1.124333</td>\n",
       "      <td>-1.052593</td>\n",
       "      <td>-0.979773</td>\n",
       "      <td>-0.909223</td>\n",
       "      <td>-0.842975</td>\n",
       "      <td>0.296119</td>\n",
       "      <td>0.251685</td>\n",
       "      <td>0.206178</td>\n",
       "      <td>0.160164</td>\n",
       "      <td>0.114187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage      educ     educ2     educ3     educ4     educ5       age  \\\n",
       "0 -0.467520 -0.668851 -0.681389 -0.683465 -0.677116 -0.664268 -0.669710   \n",
       "1 -0.371019  2.064038  2.223684  2.379630  2.530868  2.675999  1.261947   \n",
       "2 -0.328955  0.242112  0.157854  0.074845 -0.003836 -0.075928 -0.025824   \n",
       "3 -0.761969 -0.668851 -0.681389 -0.683465 -0.677116 -0.664268 -0.347767   \n",
       "4 -0.979713 -1.124333 -1.052593 -0.979773 -0.909223 -0.842975  0.296119   \n",
       "\n",
       "       age2      age3      age4      age5  \n",
       "0 -0.691203 -0.708954 -0.723031 -0.733576  \n",
       "1  1.281608  1.297931  1.310810  1.320211  \n",
       "2 -0.072282 -0.117721 -0.161641 -0.203607  \n",
       "3 -0.386577 -0.422573 -0.455483 -0.485129  \n",
       "4  0.251685  0.206178  0.160164  0.114187  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making our dataframe a pandas dataframe: \n",
    "df_sc = pd.DataFrame(df_sc, columns=df.columns)\n",
    "df_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>935.0</td>\n",
       "      <td>9.579455e+05</td>\n",
       "      <td>4.043608e+05</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>669000.0</td>\n",
       "      <td>905000.0</td>\n",
       "      <td>1160000.0</td>\n",
       "      <td>3078000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>935.0</td>\n",
       "      <td>1.346845e+01</td>\n",
       "      <td>2.196654e+00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ2</th>\n",
       "      <td>935.0</td>\n",
       "      <td>1.862193e+02</td>\n",
       "      <td>6.199373e+01</td>\n",
       "      <td>81.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ3</th>\n",
       "      <td>935.0</td>\n",
       "      <td>2.643721e+03</td>\n",
       "      <td>1.340538e+03</td>\n",
       "      <td>729.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>5832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ4</th>\n",
       "      <td>935.0</td>\n",
       "      <td>3.851672e+04</td>\n",
       "      <td>2.627353e+04</td>\n",
       "      <td>6561.0</td>\n",
       "      <td>20736.0</td>\n",
       "      <td>20736.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>104976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ5</th>\n",
       "      <td>935.0</td>\n",
       "      <td>5.751197e+05</td>\n",
       "      <td>4.914620e+05</td>\n",
       "      <td>59049.0</td>\n",
       "      <td>248832.0</td>\n",
       "      <td>248832.0</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>1889568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>935.0</td>\n",
       "      <td>3.308021e+01</td>\n",
       "      <td>3.107803e+00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age2</th>\n",
       "      <td>935.0</td>\n",
       "      <td>1.103949e+03</td>\n",
       "      <td>2.069222e+02</td>\n",
       "      <td>784.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age3</th>\n",
       "      <td>935.0</td>\n",
       "      <td>3.716073e+04</td>\n",
       "      <td>1.040078e+04</td>\n",
       "      <td>21952.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>35937.0</td>\n",
       "      <td>46656.0</td>\n",
       "      <td>54872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age4</th>\n",
       "      <td>935.0</td>\n",
       "      <td>1.261474e+06</td>\n",
       "      <td>4.676613e+05</td>\n",
       "      <td>614656.0</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>1185921.0</td>\n",
       "      <td>1679616.0</td>\n",
       "      <td>2085136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age5</th>\n",
       "      <td>935.0</td>\n",
       "      <td>4.317175e+07</td>\n",
       "      <td>1.983487e+07</td>\n",
       "      <td>17210368.0</td>\n",
       "      <td>24300000.0</td>\n",
       "      <td>39135393.0</td>\n",
       "      <td>60466176.0</td>\n",
       "      <td>79235168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count          mean           std         min         25%         50%  \\\n",
       "wage   935.0  9.579455e+05  4.043608e+05    115000.0    669000.0    905000.0   \n",
       "educ   935.0  1.346845e+01  2.196654e+00         9.0        12.0        12.0   \n",
       "educ2  935.0  1.862193e+02  6.199373e+01        81.0       144.0       144.0   \n",
       "educ3  935.0  2.643721e+03  1.340538e+03       729.0      1728.0      1728.0   \n",
       "educ4  935.0  3.851672e+04  2.627353e+04      6561.0     20736.0     20736.0   \n",
       "educ5  935.0  5.751197e+05  4.914620e+05     59049.0    248832.0    248832.0   \n",
       "age    935.0  3.308021e+01  3.107803e+00        28.0        30.0        33.0   \n",
       "age2   935.0  1.103949e+03  2.069222e+02       784.0       900.0      1089.0   \n",
       "age3   935.0  3.716073e+04  1.040078e+04     21952.0     27000.0     35937.0   \n",
       "age4   935.0  1.261474e+06  4.676613e+05    614656.0    810000.0   1185921.0   \n",
       "age5   935.0  4.317175e+07  1.983487e+07  17210368.0  24300000.0  39135393.0   \n",
       "\n",
       "              75%         max  \n",
       "wage    1160000.0   3078000.0  \n",
       "educ         16.0        18.0  \n",
       "educ2       256.0       324.0  \n",
       "educ3      4096.0      5832.0  \n",
       "educ4     65536.0    104976.0  \n",
       "educ5   1048576.0   1889568.0  \n",
       "age          36.0        38.0  \n",
       "age2       1296.0      1444.0  \n",
       "age3      46656.0     54872.0  \n",
       "age4    1679616.0   2085136.0  \n",
       "age5   60466176.0  79235168.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at variables statistical descriptions: \n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6684939913158835"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying that the standardization was carried out accurately:\n",
    "(12-13.46845)/2.196654\n",
    "\n",
    "# standardization accurate, as the result shows below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wage', 'educ', 'educ2', 'educ3', 'educ4', 'educ5', 'age', 'age2',\n",
       "       'age3', 'age4', 'age5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question2) Define your feature space and target variables and then split the data into test (20%) and train set (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>educ</th>\n",
       "      <th>educ2</th>\n",
       "      <th>educ3</th>\n",
       "      <th>educ4</th>\n",
       "      <th>educ5</th>\n",
       "      <th>age</th>\n",
       "      <th>age2</th>\n",
       "      <th>age3</th>\n",
       "      <th>age4</th>\n",
       "      <th>age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>-0.668851</td>\n",
       "      <td>-0.681389</td>\n",
       "      <td>-0.683465</td>\n",
       "      <td>-0.677116</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>-1.635539</td>\n",
       "      <td>-1.547054</td>\n",
       "      <td>-1.463051</td>\n",
       "      <td>-1.383830</td>\n",
       "      <td>-1.309577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-1.124333</td>\n",
       "      <td>-1.052593</td>\n",
       "      <td>-0.979773</td>\n",
       "      <td>-0.909223</td>\n",
       "      <td>-0.842975</td>\n",
       "      <td>1.261947</td>\n",
       "      <td>1.281608</td>\n",
       "      <td>1.297931</td>\n",
       "      <td>1.310810</td>\n",
       "      <td>1.320211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1.608556</td>\n",
       "      <td>1.658809</td>\n",
       "      <td>1.693718</td>\n",
       "      <td>1.713830</td>\n",
       "      <td>1.719745</td>\n",
       "      <td>1.583890</td>\n",
       "      <td>1.644257</td>\n",
       "      <td>1.703790</td>\n",
       "      <td>1.762179</td>\n",
       "      <td>1.819156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-0.668851</td>\n",
       "      <td>-0.681389</td>\n",
       "      <td>-0.683465</td>\n",
       "      <td>-0.677116</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>0.940004</td>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.913427</td>\n",
       "      <td>0.894592</td>\n",
       "      <td>0.872387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-0.668851</td>\n",
       "      <td>-0.681389</td>\n",
       "      <td>-0.683465</td>\n",
       "      <td>-0.677116</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>-0.669710</td>\n",
       "      <td>-0.691203</td>\n",
       "      <td>-0.708954</td>\n",
       "      <td>-0.723031</td>\n",
       "      <td>-0.733576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         educ     educ2     educ3     educ4     educ5       age      age2  \\\n",
       "932 -0.668851 -0.681389 -0.683465 -0.677116 -0.664268 -1.635539 -1.547054   \n",
       "82  -1.124333 -1.052593 -0.979773 -0.909223 -0.842975  1.261947  1.281608   \n",
       "370  1.608556  1.658809  1.693718  1.713830  1.719745  1.583890  1.644257   \n",
       "452 -0.668851 -0.681389 -0.683465 -0.677116 -0.664268  0.940004  0.928630   \n",
       "132 -0.668851 -0.681389 -0.683465 -0.677116 -0.664268 -0.669710 -0.691203   \n",
       "\n",
       "         age3      age4      age5  \n",
       "932 -1.463051 -1.383830 -1.309577  \n",
       "82   1.297931  1.310810  1.320211  \n",
       "370  1.703790  1.762179  1.819156  \n",
       "452  0.913427  0.894592  0.872387  \n",
       "132 -0.708954 -0.723031 -0.733576  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data:\n",
    "\n",
    "y = df_sc['wage'] \n",
    "X = df_sc.drop('wage', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=rand_state)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We could see that the coefficients are highly correlated with each other. We will run a linear regression and use result as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will verify if our dataframe split is accurate (80% training, 20% test):\n",
    "np.round(len(X_train)/len(X),3)\n",
    "\n",
    "# Our split shows that it was done correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question3) As a benchmark, use sm.OLS() function from statsmodel.api package to run the linear regression model on the train set\n",
    "    1) Report the summary output?\n",
    "    2) What is R^2 of the model in train set?\n",
    "    3) Are any of the features statistically significant at 5% level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing constant as the author's packet did not include constants for dataframes:\n",
    "X_test_ncos = sm.add_constant(X_test)\n",
    "X_train_ncos = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>   0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>2.83e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:46:21</td>     <th>  Log-Likelihood:    </th> <td> -1016.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   748</td>      <th>  AIC:               </th> <td>   2054.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   737</td>      <th>  BIC:               </th> <td>   2105.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0028</td> <td>    0.035</td> <td>   -0.080</td> <td> 0.937</td> <td>   -0.071</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>  <td> -109.9917</td> <td>  192.003</td> <td>   -0.573</td> <td> 0.567</td> <td> -486.931</td> <td>  266.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ2</th> <td>  462.5622</td> <td>  824.114</td> <td>    0.561</td> <td> 0.575</td> <td>-1155.328</td> <td> 2080.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ3</th> <td> -736.3809</td> <td> 1339.181</td> <td>   -0.550</td> <td> 0.583</td> <td>-3365.445</td> <td> 1892.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ4</th> <td>  527.4761</td> <td>  974.843</td> <td>    0.541</td> <td> 0.589</td> <td>-1386.323</td> <td> 2441.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ5</th> <td> -143.4145</td> <td>  267.848</td> <td>   -0.535</td> <td> 0.593</td> <td> -669.250</td> <td>  382.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>   <td>-1295.3370</td> <td> 4397.692</td> <td>   -0.295</td> <td> 0.768</td> <td>-9928.834</td> <td> 7338.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age2</th>  <td> 5164.4620</td> <td> 1.79e+04</td> <td>    0.289</td> <td> 0.773</td> <td>-2.99e+04</td> <td> 4.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age3</th>  <td>-7783.0117</td> <td> 2.73e+04</td> <td>   -0.285</td> <td> 0.776</td> <td>-6.15e+04</td> <td> 4.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age4</th>  <td> 5255.0538</td> <td> 1.87e+04</td> <td>    0.282</td> <td> 0.778</td> <td>-3.14e+04</td> <td> 4.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age5</th>  <td>-1341.0610</td> <td> 4794.082</td> <td>   -0.280</td> <td> 0.780</td> <td>-1.08e+04</td> <td> 8070.622</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>202.208</td> <th>  Durbin-Watson:     </th> <td>   1.936</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 653.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.286</td>  <th>  Prob(JB):          </th> <td>1.40e-142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.787</td>  <th>  Cond. No.          </th> <td>2.44e+06</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.44e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   wage   R-squared:                       0.128\n",
       "Model:                            OLS   Adj. R-squared:                  0.116\n",
       "Method:                 Least Squares   F-statistic:                     10.81\n",
       "Date:                Thu, 25 Feb 2021   Prob (F-statistic):           2.83e-17\n",
       "Time:                        12:46:21   Log-Likelihood:                -1016.0\n",
       "No. Observations:                 748   AIC:                             2054.\n",
       "Df Residuals:                     737   BIC:                             2105.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0028      0.035     -0.080      0.937      -0.071       0.065\n",
       "educ        -109.9917    192.003     -0.573      0.567    -486.931     266.947\n",
       "educ2        462.5622    824.114      0.561      0.575   -1155.328    2080.452\n",
       "educ3       -736.3809   1339.181     -0.550      0.583   -3365.445    1892.684\n",
       "educ4        527.4761    974.843      0.541      0.589   -1386.323    2441.276\n",
       "educ5       -143.4145    267.848     -0.535      0.593    -669.250     382.421\n",
       "age        -1295.3370   4397.692     -0.295      0.768   -9928.834    7338.160\n",
       "age2        5164.4620   1.79e+04      0.289      0.773   -2.99e+04    4.03e+04\n",
       "age3       -7783.0117   2.73e+04     -0.285      0.776   -6.15e+04    4.59e+04\n",
       "age4        5255.0538   1.87e+04      0.282      0.778   -3.14e+04    4.19e+04\n",
       "age5       -1341.0610   4794.082     -0.280      0.780   -1.08e+04    8070.622\n",
       "==============================================================================\n",
       "Omnibus:                      202.208   Durbin-Watson:                   1.936\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              653.255\n",
       "Skew:                           1.286   Prob(JB):                    1.40e-142\n",
       "Kurtosis:                       6.787   Cond. No.                     2.44e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.44e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model using the OLS method and reporting output:\n",
    "model = sm.OLS(y_train, X_train_ncos).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reporting R^2 of the model in train set:\n",
    "\n",
    "The R^2 is approximatley 13% and the adjusted R^2 is about 12%. This is not a very high R^2 and thus our OLS model\n",
    "does an okay job at explainaing the variance in the wage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reporting the statistical significance of our features:\n",
    "\n",
    "Given the high p-values of our coefficients, we none of our features are statistically significant, which would also           explain the low R squared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question4) importing the functions for Linear Regression, Ridge, Lasso and ElasticNet regression functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question4, subquestion1) Train all the 4 models with the default features:\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "model_ridge = Ridge()\n",
    "model_lasso = Lasso()\n",
    "model_net = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the predicted values for the test set for each model:\n",
    "\n",
    "y_hat_linear = model_linear.fit(X_train, y_train).predict(X_test)\n",
    "y_hat_ridge = model_ridge.fit(X_train, y_train).predict(X_test)\n",
    "y_hat_lasso = model_lasso.fit(X_train, y_train).predict(X_test)\n",
    "y_hat_net = model_net.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_hat_linear</th>\n",
       "      <th>y_hat_ridge</th>\n",
       "      <th>y_hat_lasso</th>\n",
       "      <th>y_hat_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.042199</td>\n",
       "      <td>-0.267170</td>\n",
       "      <td>-0.202696</td>\n",
       "      <td>-0.012852</td>\n",
       "      <td>-0.012852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1.910343</td>\n",
       "      <td>0.699718</td>\n",
       "      <td>0.704007</td>\n",
       "      <td>-0.012852</td>\n",
       "      <td>-0.012852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>-0.700110</td>\n",
       "      <td>-0.065042</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>-0.012852</td>\n",
       "      <td>-0.012852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2.328510</td>\n",
       "      <td>0.689508</td>\n",
       "      <td>0.653410</td>\n",
       "      <td>-0.012852</td>\n",
       "      <td>-0.012852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1.341239</td>\n",
       "      <td>0.208652</td>\n",
       "      <td>0.171149</td>\n",
       "      <td>-0.012852</td>\n",
       "      <td>-0.012852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_test  y_hat_linear  y_hat_ridge  y_hat_lasso  y_hat_net\n",
       "434  0.042199     -0.267170    -0.202696    -0.012852  -0.012852\n",
       "238  1.910343      0.699718     0.704007    -0.012852  -0.012852\n",
       "531 -0.700110     -0.065042     0.045579    -0.012852  -0.012852\n",
       "157  2.328510      0.689508     0.653410    -0.012852  -0.012852\n",
       "601  1.341239      0.208652     0.171149    -0.012852  -0.012852"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a data farame and naming it df_predictions, then will display the predictions of each model:\n",
    "df_predictions = pd.DataFrame({'y_test':y_test,\n",
    "                               'y_hat_linear':y_hat_linear,\n",
    "                               'y_hat_ridge':y_hat_ridge,\n",
    "                               'y_hat_lasso':y_hat_lasso,\n",
    "                               'y_hat_net':y_hat_net})\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Because the features were all statistically insigificant, we could see that lasso and elastic net regressions predict close to zero values and the values we see -.0128552 are just the mean of the target variable. They penalize the model for the features with statistical insigificance. We could see that this is different for the ridge and ols linear regressions. Ridge only shrinks the features coefficients and does not get rid of them. So, we see the target variable mean and the little that's left from shrinking the features' coefficients. OLS keeps the coefficients, so we see hire values for the features. There is no penalty for the inclusion of statistically insigificant variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['educ', 'educ2', 'educ3', 'educ4', 'educ5', 'age', 'age2', 'age3',\n",
       "       'age4', 'age5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the features while the target variable is dropped:\n",
    "df_sc.drop('wage', axis=1, inplace=False).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>model_lin</th>\n",
       "      <th>model_ridge</th>\n",
       "      <th>model_lasso</th>\n",
       "      <th>model_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>educ</td>\n",
       "      <td>-109.991745</td>\n",
       "      <td>0.169172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>educ2</td>\n",
       "      <td>462.562174</td>\n",
       "      <td>0.309854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>educ3</td>\n",
       "      <td>-736.380870</td>\n",
       "      <td>0.232209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>educ4</td>\n",
       "      <td>527.476085</td>\n",
       "      <td>-0.016857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>educ5</td>\n",
       "      <td>-143.414487</td>\n",
       "      <td>-0.393124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>-1295.337040</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age2</td>\n",
       "      <td>5164.461994</td>\n",
       "      <td>0.136966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age3</td>\n",
       "      <td>-7783.011668</td>\n",
       "      <td>0.147814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>age4</td>\n",
       "      <td>5255.053781</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>age5</td>\n",
       "      <td>-1341.061044</td>\n",
       "      <td>-0.166490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Features    model_lin  model_ridge  model_lasso  model_net\n",
       "0     educ  -109.991745     0.169172          0.0        0.0\n",
       "1    educ2   462.562174     0.309854          0.0        0.0\n",
       "2    educ3  -736.380870     0.232209          0.0        0.0\n",
       "3    educ4   527.476085    -0.016857          0.0        0.0\n",
       "4    educ5  -143.414487    -0.393124          0.0        0.0\n",
       "5      age -1295.337040     0.005242          0.0        0.0\n",
       "6     age2  5164.461994     0.136966          0.0        0.0\n",
       "7     age3 -7783.011668     0.147814          0.0        0.0\n",
       "8     age4  5255.053781     0.043936          0.0        0.0\n",
       "9     age5 -1341.061044    -0.166490          0.0        0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating the coefficients of each model and staking them together, then assigning them a name:\n",
    "\n",
    "coefficients = pd.DataFrame({'Features':df.drop('wage', axis=1, inplace=False).columns})\n",
    "coefficients['model_lin']= model_linear.coef_\n",
    "coefficients['model_ridge']= model_ridge.coef_\n",
    "coefficients['model_lasso']= model_lasso.coef_\n",
    "coefficients['model_net']= model_net.coef_\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso and net penalize the model for all features, because they were are all statistically insigificant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Question5) Use Cross Validation to find the optimal alpha for each regression technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Optimal alpha for Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv= RidgeCV()\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ridge_opt = ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Optimal alpha for Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0951053471638943, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16159752254600335, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.22387414093077496, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27818324909594594, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.323659934579382, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3607577597059617, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3888865946431679, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41108135885247066, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.42992178649296875, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08548698954302836, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14763967355008845, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20589279429736962, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2565829307634431, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29888072981589175, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3341490840358574, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3661481702367837, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19718460487217726, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4130230775581367, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7180287047772822, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.119919578441909, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6265863591333982, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2460114212606186, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0678258205974771, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14042901851951228, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21565640919698126, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28627398691969574, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34916327291409743, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4034165469980735, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4492618128097092, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4874602988230663, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5189746447069865, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5447922519575741, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08829331968343013, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15038149301028625, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20844003587535553, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2589276657967048, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3010658344890089, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.33534575597377625, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.36276265112644523, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3844342156419316, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.40142203304878876, tolerance: 0.06053190034407858\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.059092699435097984, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12129685233782084, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18407368728077245, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2417601459573575, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11115264889457421, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3889827374771926, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7963061643102378, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3037263060434725, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.887727843429559, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.52943390748419, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.205817134594156, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.088238584570092, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.028344059461119, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010732138475800224"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv = LassoCV()\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_lasso_opt = lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Optimal alpha for Elastic Net regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13030236469467127, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.23122915544263378, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29221864809210274, tolerance: 0.06204532770253077\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0922788809037911, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17691769066993857, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2246243310527234, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2634509744799516, tolerance: 0.06248847531197081\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15061568824546612, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2446633994095464, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3040531497082384, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3541391034600565, tolerance: 0.06452160418012512\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06547716335307996, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07463285424427113, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09172404018926272, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11563496883911739, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06205040105430726, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0777093323777649, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10001303304977682, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12962961983123478, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16803900311100506, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21727881099053548, tolerance: 0.054213241540790776\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010682821217946607"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnetcv = ElasticNetCV()\n",
    "elasticnetcv.fit(X_train, y_train)\n",
    "elasticnetcv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnetcv.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_elasticnet_opt = elasticnetcv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question6) Now, we will go back to part 4, then refit the models using the optimal alphas we computed above from cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plugging in the optial alphas into the models:\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "model_ridge = Ridge(10.0)\n",
    "model_lasso = Lasso(0.010732138475800224)\n",
    "model_net = ElasticNet(0.010682821217946607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the predicted values for the test set for each model and seeing the effect with new optimal alphas:\n",
    "\n",
    "y_hat_linear = model_linear.fit(X_train, y_train).predict(X_test)\n",
    "y_hat_ridge = model_ridge.fit(X_train, y_train).predict(X_test)\n",
    "y_hat_lasso = model_lasso.fit(X_train, y_train).predict(X_test)\n",
    "y_hat_net = model_net.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_hat_linear</th>\n",
       "      <th>y_hat_ridge</th>\n",
       "      <th>y_hat_lasso</th>\n",
       "      <th>y_hat_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.042199</td>\n",
       "      <td>-0.267170</td>\n",
       "      <td>-0.207593</td>\n",
       "      <td>-0.213254</td>\n",
       "      <td>-0.214806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1.910343</td>\n",
       "      <td>0.699718</td>\n",
       "      <td>0.755765</td>\n",
       "      <td>0.808387</td>\n",
       "      <td>0.809270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>-0.700110</td>\n",
       "      <td>-0.065042</td>\n",
       "      <td>0.052495</td>\n",
       "      <td>0.023871</td>\n",
       "      <td>0.037489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2.328510</td>\n",
       "      <td>0.689508</td>\n",
       "      <td>0.700613</td>\n",
       "      <td>0.761422</td>\n",
       "      <td>0.757606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1.341239</td>\n",
       "      <td>0.208652</td>\n",
       "      <td>0.165839</td>\n",
       "      <td>0.155527</td>\n",
       "      <td>0.158446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_test  y_hat_linear  y_hat_ridge  y_hat_lasso  y_hat_net\n",
       "434  0.042199     -0.267170    -0.207593    -0.213254  -0.214806\n",
       "238  1.910343      0.699718     0.755765     0.808387   0.809270\n",
       "531 -0.700110     -0.065042     0.052495     0.023871   0.037489\n",
       "157  2.328510      0.689508     0.700613     0.761422   0.757606\n",
       "601  1.341239      0.208652     0.165839     0.155527   0.158446"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_optimal = pd.DataFrame({'y_test':y_test,\n",
    "                               'y_hat_linear':y_hat_linear,\n",
    "                               'y_hat_ridge':y_hat_ridge,\n",
    "                               'y_hat_lasso':y_hat_lasso,\n",
    "                               'y_hat_net':y_hat_net})\n",
    "df_predictions_optimal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance in the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question7) Report the RMSE of the test set for all four models, rank models based on their performance. Were you able to beat the simple linear model. What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_test = np.mean(np.square(df_predictions_optimal['y_test'] - df_predictions_optimal['y_hat_linear']))\n",
    "RMSE_test = np.sqrt(MSE_test)\n",
    "np.round(RMSE_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_test = np.mean(np.square(df_predictions_optimal['y_test'] - df_predictions_optimal['y_hat_ridge']))\n",
    "RMSE_test = np.sqrt(MSE_test)\n",
    "np.round(RMSE_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_test = np.mean(np.square(df_predictions_optimal['y_test'] - df_predictions_optimal['y_hat_lasso']))\n",
    "RMSE_test = np.sqrt(MSE_test)\n",
    "np.round(RMSE_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_test = np.mean(np.square(df_predictions_optimal['y_test'] - df_predictions_optimal['y_hat_net']))\n",
    "RMSE_test = np.sqrt(MSE_test)\n",
    "np.round(RMSE_test,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the RMSE of all our models are very, very close now after we plugged in the optimal alpha we got from our regressions. We would not say that we beat the simple linear model, because they are extremely close. We could fairly say they are about the same. We could understand why Lasso and ElasticNet have higher RMSE, because they are penalizing the features in our regression model. They were all statistically insigificant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the coefficients vs alphas for each of the penalized models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_ridge = 10**np.linspace(-4,2,100)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(alpha_ridge,'or' )\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('alpha (lambda)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
