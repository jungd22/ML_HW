{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8: Group 1\n",
    "#### SVM (Logan Housing Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Jung, Ryan Voges, Emily Blake, Spencer Powell, Abraham Alhomadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 EDA (30 points)\n",
    "In this exercise I want you to do a quick EDA on the Logan housing data set. The\n",
    "data are 4110 observations of Logan housing prices from 2018 to 2020. All the variable\n",
    "names are self explanatory except the DOM which stands for Days On the Market. The\n",
    "data was originally provided to the course by Jeffrey! Jeff is working on this exciting\n",
    "dataset for his masterâ€™s thesis. Please do not share this data set with anyone outside\n",
    "of the class.\n",
    "\n",
    "Show me what you have learned from the previous EDAs you did in HW2 and HW3.\n",
    "Try to come up with an interesting story (hypothesis) using this data set. For example,\n",
    "that would be interesting to see the breakdowns of Logan house prices by year, location\n",
    "etc. Treat this exercise as a real world project. Many times the managers have no idea\n",
    "what they want from the data!! your job is to be as creative as possible and come up\n",
    "with informative charts and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Logan_housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4110 entries, 0 to 4109\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Sold Price         4110 non-null   int64 \n",
      " 1   DOM                4110 non-null   int64 \n",
      " 2   Garage Capacity    4110 non-null   int64 \n",
      " 3   HOA Fee            4110 non-null   int64 \n",
      " 4   Irregular Shape    4110 non-null   object\n",
      " 5   Quadrant           4110 non-null   object\n",
      " 6   School District    4110 non-null   object\n",
      " 7   Sold Terms         4110 non-null   object\n",
      " 8   Total Bedrooms     4110 non-null   int64 \n",
      " 9   Total Bathrooms    4110 non-null   int64 \n",
      " 10  Total Square Feet  4110 non-null   int64 \n",
      " 11  Year Built         4110 non-null   int64 \n",
      " 12  Zip                4110 non-null   int64 \n",
      " 13  year_sold          4110 non-null   int64 \n",
      " 14  month_sold         4110 non-null   int64 \n",
      " 15  built_after_2000   4110 non-null   int64 \n",
      "dtypes: int64(12), object(4)\n",
      "memory usage: 513.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sold Price           0\n",
       "DOM                  0\n",
       "Garage Capacity      0\n",
       "HOA Fee              0\n",
       "Irregular Shape      0\n",
       "Quadrant             0\n",
       "School District      0\n",
       "Sold Terms           0\n",
       "Total Bedrooms       0\n",
       "Total Bathrooms      0\n",
       "Total Square Feet    0\n",
       "Year Built           0\n",
       "Zip                  0\n",
       "year_sold            0\n",
       "month_sold           0\n",
       "built_after_2000     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>DOM</th>\n",
       "      <th>Garage Capacity</th>\n",
       "      <th>HOA Fee</th>\n",
       "      <th>Irregular Shape</th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>School District</th>\n",
       "      <th>Sold Terms</th>\n",
       "      <th>Total Bedrooms</th>\n",
       "      <th>Total Bathrooms</th>\n",
       "      <th>Total Square Feet</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Zip</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>built_after_2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NW</td>\n",
       "      <td>Cache</td>\n",
       "      <td>FHA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1031</td>\n",
       "      <td>1974</td>\n",
       "      <td>84335</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NW</td>\n",
       "      <td>Cache</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2091</td>\n",
       "      <td>1995</td>\n",
       "      <td>84335</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>274900</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NW</td>\n",
       "      <td>Cache</td>\n",
       "      <td>Conventional</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1980</td>\n",
       "      <td>84335</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175000</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NW</td>\n",
       "      <td>Cache</td>\n",
       "      <td>USDA Rural Development</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1920</td>\n",
       "      <td>1978</td>\n",
       "      <td>84335</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179000</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NW</td>\n",
       "      <td>Cache</td>\n",
       "      <td>Cash</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1329</td>\n",
       "      <td>1976</td>\n",
       "      <td>84335</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sold Price  DOM  Garage Capacity  HOA Fee Irregular Shape Quadrant  \\\n",
       "0      176000    5                2        0              No       NW   \n",
       "1      225000    6                2        0              No       NW   \n",
       "2      274900   14                2        0              No       NW   \n",
       "3      175000   16                1        0              No       NW   \n",
       "4      179000   29                0        0              No       NW   \n",
       "\n",
       "  School District              Sold Terms  Total Bedrooms  Total Bathrooms  \\\n",
       "0           Cache                     FHA               3                1   \n",
       "1           Cache            Conventional               4                2   \n",
       "2           Cache            Conventional               3                1   \n",
       "3           Cache  USDA Rural Development               4                1   \n",
       "4           Cache                    Cash               4                2   \n",
       "\n",
       "   Total Square Feet  Year Built    Zip  year_sold  month_sold  \\\n",
       "0               1031        1974  84335       2018           9   \n",
       "1               2091        1995  84335       2018           7   \n",
       "2               2016        1980  84335       2018          11   \n",
       "3               1920        1978  84335       2018           6   \n",
       "4               1329        1976  84335       2018           9   \n",
       "\n",
       "   built_after_2000  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 SVM Regression (60 points)\n",
    "\n",
    "1. Define the categorical variables and transform them into dummy variables (if you\n",
    "havenâ€™t done this already in Question 1). (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scale all the variables using standardization. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define the feature space and target variables. Split the data into test (20%) and\n",
    "train set (80%) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. From sklearn.svm import the relevant function for SVM regression. Do the followings: (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Train the regression model using its default inputs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make predictions on the test set and save them as y hat (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Construct a data frame named df predictions with 2 columns. y test, and\n",
    "y hat from previous part (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Visualize actual vs predicted prices in the test set using an scatter plot. Are you visually satisfied with the regression model? (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Report the R squared and the RMSE in the test set. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tuning the hyperparameters using gridsearchCV. I want you to specifically use the following param grid. my param grid = â€™Câ€™: [1,10,100], â€™gammaâ€™: [â€™scaledâ€™,0.1,0.01], â€™kernelâ€™: [â€™rbf â€™] (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Re-estimate (Re-fit) the SVM regression model with the optimal parameters from the gridsearch method. Save the predictions as y hat optimized and add this column to the df predictions data frame from part 4.3 in Question 2. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Report the optimized R-squared and RMSE in the test set and compare them with the outputs from part 4.5 in Question 2. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Estimate the optimized RMSE test using 5 fold cross validation. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 SVM Classification (65 points)\n",
    "Jeff is specifically interested in the DOM variable (Days on the Market) and he wants to make a classifier that predicts if a new listing will be liquid enough or not? i.e. the number of days on the market (for a new listing) is above or below the average DOM. Unfortunately Jeff has not taken the machine learning course yet and he doesnâ€™t know how to apply SVM classification. Could you help him out with the following tasks?\n",
    "\n",
    "1. Define a binary target variable liquid. liquid = 1 if DOM < average(DOM) and 0 otherwise. What are the proportions of liquid listings vs illiquid ones in the data set? Is the target variable (relatively) balanced or (relatively) imbalanced? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Along with the target variable, define your feature space (X) and split the data into test (20%) and train set (80%) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. From sklearn.svm import the relevant function for SVM classification. Do the followings: (30 points)\n",
    "\n",
    "a) Train the SVM classification model using its default inputs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make classifications on the test set and save them as y hat (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Construct a data frame named df classifications with 2 columns. y test, and y hat from previous part (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Borrow my SVM report() function from the python notebook of the SVM lecture. Report the Accuracy, precision, recall and f1 score along with the confusion matrix. Interpret all of these statistics. Do you trust the accuracy of the model? why? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Can you plot the ROC curve and report the AUC score in SVM classification? why? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tuning the hyperparameters using gridsearchCV. I want you to specifically use the following param grid. my param grid = â€™Câ€™: [1,100,1000], â€™gammaâ€™: [â€™scaledâ€™,0.01,0.001], â€™kernelâ€™: [â€™rbf â€™] (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Re-estimate (Re-fit) the SVM classification model with the optimal parameters from the gridsearch method. Save the predictions as y hat optimized and add this column to the df classifications data frame from part 3.3 in Question 3. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Report the optimized classification metrics using my SVM report() function and compare them with the outputs from part 3.4 in Question3. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Estimate the optimized accuracy test using 5 fold cross validation. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Why do you think Jeff is interested in predicting the liquidity premium (either positive or negative) of the houses? There may be multiple correct answers to this question. Just list whatever reason seems appropriate to you. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
